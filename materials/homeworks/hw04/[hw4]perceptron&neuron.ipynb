{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Школа глубокого обучения\n",
    "\n",
    "<a href=\"https://mipt.ru/science/labs/laboratoriya-neyronnykh-sistem-i-glubokogo-obucheniya/\"><img align=\"right\" src=\"https://avatars1.githubusercontent.com/u/29918795?v=4&s=200\" alt=\"DeepHackLab\" style=\"position:relative;top:-40px;right:10px;height:100px;\" /></a>\n",
    "\n",
    "\n",
    "\n",
    "### Физтех-Школа Прикладной математики и информатики МФТИ \n",
    "### Лаборатория нейронных сетей и глубокого обучения (DeepHackLab)\n",
    "*Дедлайн -- 25 ноября.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Захаркин Илья (ФИВТ МФТИ), Хахулин Тарас (ФРТК МФТИ)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перед началом выполнения задания настоятельно рекомендуется посмотреть [лекцию](https://vk.com/doc83865491_454180587?hash=37e49000cda3837459&dl=cf3df2e170d9d05351) и прорешать задания в [ноутбуке с семинара](https://github.com/deepmipt/dlschl/blob/master/materials/%5Blesson3%5Dperceptron/%5Bsem3%5DPerceptron_seminar.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 4\n",
    "### Реализация перцептрона и нейрона с сигмоидальной функцией активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Поздравляем! :) **  \n",
    "Это Ваше первое домашнее задание на нейронные сети, ведь один нейрон - это неотъемлимая составляющая любой глубокой сети, которые на сегодняший день используются повсеместно (и которые Вам предстоит изучить далее по курсу). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании Вам нужно будет: \n",
    "- самостоятельно реализовать класс **`Perceptron()`** с пороговой функцией активации\n",
    "- обучить и протестировать Ваш нейрон на сгенерированных и реальных данных (файлы с реальными данными помещены в папку /data в этой же директории)\n",
    "- сравнить качество работы Вашего класса с классом из библиотеки `scikit-learn` (`sklearn.linear_model.Perceptron()`)\n",
    "- самостоятельно реализовать класс Neuron() с сигмоидной функцией активации и самостоятельно протестировать его"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Небольшое введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://blog.radario.ru/wp-content/uploads/2017/05/model.png\" style=\"width:750px;height:300px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(на картинке получается, что \"алгоритм\" и \"модель\" - разные вещи, но в машинном обучении их обычно считают синонимами, то есть \"алгоритм\" = \"модель\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти любой алгоритм машинного обучения, решающий задачу *классификации* или *регрессии*, работает так:\n",
    "\n",
    "1. (*стадия инициализации*) Задаются его **гиперпараметры**, то есть те величины, которые не \"выучиваются\" алгоритмом в процессе обучения самостоятельно \n",
    "2. (*стадия обучения*) Алгоритм запускается на данных, **обучаясь** на них и меняя свои **параметры** (не путать с *гипер*параметрами) каким-то определённым образом (например, с помощью *метода градиентного спуска*), исходя из функции потерь (её называют *loss function*). Функция потерь, по сути, говорит, где и как ошибается модель\n",
    "3.  (*стадия предсказания*) Модель готова, и теперь с помощью неё можно делать **предсказания** на новых объектах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap  # тут лежат разные штуки для цветовой магии\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1 (3 балла)\n",
    "#### Класс Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В даном разделе будет решаться задача **бинарной классификации** с помощью перцептрона:  \n",
    "- *Входные данные*: матрица $X$ размера $(n, m)$ и столбец $y$ из нулей и единиц размера $(n, 1)$. Строкам матрицы соответствуют объекты, столбцам - признаки (то есть строка $i$ есть набор признаков (*признаковое описание*) объекта $x_i$).\n",
    "- *Выходные данные*: столбец $\\hat{y}$ из нулей и единиц размера $(n, 1)$ - предсказания алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Краткая справка по перцептрону (было на занятии):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перцептрон взвешивает входы с определёнными весами и выдаёт результат в виде пороговой функции от взвешенной суммы:\n",
    "![title](./perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять, как мы будем обновлять параметры модели (веса), нужно знать, какую функцию потерь мы оптимизируем (находим минимум). В данном случае мы решаем задачу бинарной классификации (2 класса: 1 или 0), возьмём в качестве функции потерь среднеквадратичную ошибку:\n",
    "$$J(w, x) = \\frac{1}{2n}\\sum_{i=1}^{n} (\\hat{y_i} - y_i)^2 = \\frac{1}{2n}\\sum_{i=1}^{n} (f(w \\cdot x_i) - y_i)^2$$  \n",
    "Здесь $w \\cdot x_i$ - скалярное произведение, а $f(w \\cdot x_i)$ - пороговая функция: \n",
    "$$\n",
    "f(z) =\n",
    "\\begin{cases}\n",
    "1, &\\text{если } w \\cdot x_i > 0 \\\\\n",
    "0, &\\text{если } w \\cdot x_i \\le 0\n",
    "\\end{cases}\n",
    "$$  \n",
    "\n",
    "**Примечание:** Здесь предполагается, что $b$ - свободный член - является частью вектора весов: $w_0$. Тогда, если к $X$ приписать слева единичный столбец, в скалярном произведении $b$ будет именно как свободный член."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Реализуйте функцию потерь $J$ (0.5 балла): **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def J(y_pred, y):\n",
    "    return # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку у *пороговой функции* не существует производной (Вы её график видели? Выглядит он, конечно, простым, но производная таких не любит), то мы не можем использовать градиентный спуск, ведь:\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{n} (f(w \\cdot X) - y)f^{'}(w \\cdot X)X$$ \n",
    "где $f^{'}(w \\cdot X)$ - посчитать не получится. Но ведь хочется как-то обновлять веса, иначе как обучить алгоритм отличать груши от яблок? Поэтому предлагается взять $w = w - \\alpha\\Delta{w}$, где $\\Delta{w} = \\frac{1}{n}X^T(\\hat{y} - y)$ (не забудьте, что при $w_0 = b$ признак $x_0$ = 1). Это правило является неким частным случаем градиентного спуска для данного случая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, вооружившись всеми формулами и силой духа, нужно написать свой класс **`Perceptron()`**. Уже есть код класса и немного кода реализации. По-максимуму используйте **Numpy** при реализации, т.к. будет проверяться и скорость работы Вашего алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, w=None, b=0):\n",
    "        \"\"\"\n",
    "        :param: w -- вектор весов\n",
    "        :param: b -- смещение\n",
    "        \"\"\"\n",
    "        # Пока что мы не знаем размер матрицы X, а значит не знаем, сколько будет весов\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def activate(self, x):\n",
    "        return x > 0\n",
    "        \n",
    "    def forward_pass(self, X):\n",
    "        \"\"\"\n",
    "        Рассчитывает ответ перцептрона при предъявлении набора объектов\n",
    "        :param: X -- матрица примеров размера (n, m), каждая строка - отдельный объект\n",
    "        :return: вектор размера (n, 1) из нулей и единиц с ответами перцептрона \n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        y_pred = np.zeros((n, 1))  # y_predicted - предсказанные классы\n",
    "        # Ваш код здесь\n",
    "        return y_pred\n",
    "    \n",
    "    def backward_pass(self, X, y, y_pred, learning_rate=0.005):\n",
    "        \"\"\"\n",
    "        Обновляет значения весов перцептрона в соответствии с этим объектом\n",
    "        :param: X -- матрица входов размера (n, m)\n",
    "                y -- вектор правильных ответов размера (n, 1)\n",
    "                learning_rate - \"скорость обучения\" (символ alpha в формулах выше)\n",
    "        В этом методе ничего возвращать не нужно\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "    \n",
    "    def fit(self, X, y, num_epochs=300):\n",
    "        \"\"\"\n",
    "        Спускаемся в минимум\n",
    "        :param: X -- матрица входов размера (n, m)\n",
    "                y -- вектор правильных ответов размера (n, 1)\n",
    "                num_epochs -- количество итераций обучения\n",
    "        :return: J_values -- вектор значений функции потерь\n",
    "        \"\"\"\n",
    "        self.w = np.zeros((X.shape[1], 1))  # столбец (m, 1)\n",
    "        self.b = 0  # смещение\n",
    "        J_values = []  # значения функции потерь на различных итерациях обновления весов\n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            # Ваш код здесь\n",
    "\n",
    "        return J_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Класс готов. Посмотрим, правильно ли ведёт себя Ваш перцептрон. Далее идут несколько ячеек с тестовым кодом, Вам нужно просто запустить их и проверить, чтобы результаты запуска совпадали с соответствующими числами из таблиц:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**forward_pass() (0.5 балла)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1., 2.]).reshape(2, 1)\n",
    "b = 2.\n",
    "X = np.array([[1., 2., -1.], [3., 4., -3.2]])\n",
    "\n",
    "perceptron = Perceptron(w, b)\n",
    "y_pred = perceptron.forward_pass(X.T)\n",
    "print (\"y_pred = \" + str(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Должно быть||\n",
    "|------|-------|\n",
    "|**y_pred**|[1, 1, 0]|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**backward_pass() (0.5 балла)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([1, 0, 1]).reshape(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron.backward_pass(X.T, y, y_pred)\n",
    "\n",
    "print (\"w = \" + str(perceptron.w))\n",
    "print (\"b = \" + str(perceptron.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Должно быть||\n",
    "|-|-|\n",
    "|**w**| [[ 0.995], [1.988]] |\n",
    "|**b**| 2.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Посмотрим, как меняется функция потерь в течение процесса обучения на реальных данных - датасет \"Яблоки и Груши\" из лекции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/apples_pears.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=data['target'], cmap='rainbow')\n",
    "plt.title('Яблоки и груши', fontsize=15)\n",
    "plt.xlabel('симметричность', fontsize=14)\n",
    "plt.ylabel('желтизна', fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** Какой класс соответствует яблокам (какого они цвета на графике)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** <Ваш ответ>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обозначим, что здесь признаки, а что - классы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:2].values  # матрица объекты-признаки\n",
    "y = data['target'].values.reshape((-1, 1))  # классы (столбец из нулей и единиц)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вывод функции потерь (1.5 балла) **  \n",
    "Функция потерь должна убывать и в итоге стать близкой к 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "perceptron = # Ваш код здесь\n",
    "J_values = # Ваш код здесь\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(J_values)\n",
    "plt.title('Функция потерь', fontsize=15)\n",
    "plt.xlabel('номер итерации', fontsize=14)\n",
    "plt.ylabel('$J(\\hat{y}, y)$', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как перцептрон классифицировал объекты из выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=perceptron.forward_pass(X), cmap='spring')\n",
    "plt.title('Яблоки и груши', fontsize=15)\n",
    "plt.xlabel('симметричность', fontsize=14)\n",
    "plt.ylabel('желтизна', fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой задаче нужно сравнить качество работы Вашего перцептрона и алгоритма из библиотеки `sklearn` на датасете с сайта [Kaggle](https://www.kaggle.com) - [Gender Recognition by Voice](https://www.kaggle.com/primaryobjects/voicegender). В данном датасете в качестве признаков выступают различные звуковые характеристики голоса, а в качестве классов - пол (мужчина/женщина). Подробнее о самих признаках можно почитать [на странице датасета](https://www.kaggle.com/primaryobjects/voicegender) (на английском). Нашей целью пока что является просто протестировать на этих данных два алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**! Обратите внимание на имя функции из sklearn - skPerceptron** (это сделано, чтобы не совпадало с именем Вашего класса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron as skPerceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './data/voice.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data['label'] = data['label'].apply(lambda x: 1 if x == 'male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Чтобы перемешать данные. Изначально там сначала идут все мужчины, потом все женщины\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data.iloc[:int(len(data)*0.7), :-1]  # матрица объекты-признаки\n",
    "y_train = data.iloc[:int(len(data)*0.7), -1]  # истинные значения пола (мужчина/женщина)\n",
    "\n",
    "X_test = data.iloc[int(len(data)*0.7):, :-1]  # матрица объекты-признаки\n",
    "y_test = data.iloc[int(len(data)*0.7):, -1]  # истинные значения пола (мужчина/женщина)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут нужно натренировать Ваш перцептрон и перцептрон из `sklearn` на этих данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним доли правильных ответов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Точность (доля правильных ответов, из 100%) моего перцептрона: {:d}'.format(accuracy_score(<Ваш код здесь>) * 100))\n",
    "print('Точность (доля правильных ответов) перцептрона из sklearn: {:.1f} %'.format(accuracy_score(<Ваш код здесь>) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос:** Хорошее ли качество показывает перцептрон? Как Вы думаете, почему? Можете писать любые мысли на этот счёт."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3 (5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Нейрон (сигмоидальный) (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "В данном случае мы снова решаем задачу бинарной классификации (2 класса: 1 или 0), но здесь уже будет другая функция активации:\n",
    "$$J(w, x) = \\frac{1}{2n}\\sum_{i=1}^{n} (\\hat{y_i} - y_i)^2 = \\frac{1}{2n}\\sum_{i=1}^{n} (\\sigma(w \\cdot x_i) - y_i)^2$$  \n",
    "Здесь $w \\cdot x_i$ - скалярное произведение, а $\\sigma(w \\cdot x_i) =\\frac{1}{1+e^{-w \\cdot x_i}} $ - сигмоида.  \n",
    "\n",
    "**Примечание:** Здесь предполагается, что $b$ - свободный член - является частью вектора весов и является $w_0$. Тогда, если к $X$ приписать единичный столбец, в скалярном произведении $b$ будет именно как свободный член."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула для обновления весов при градиентном спуске будут такие:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{n}\\sum_{i=1}^{n} (\\sigma(w \\cdot x_i) - y_i)\\sigma(w \\cdot x_i)(1 - \\sigma(w \\cdot x_i))x_i$$ (не забудьте, что $x_0$ = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции с семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"Сигмоидальная функция\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    \"\"\"Производная сигмоиды\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно написать нейрон с сигмоидной функцией активации. Здесь всё похоже на перцептрон, но будут по-другому обновляться веса и другая функция активации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, w=None, b=0):\n",
    "        \"\"\"\n",
    "        :param: w -- вектор весов\n",
    "        :param: b -- смещение\n",
    "        \"\"\"\n",
    "        # Пока что мы не знаем размер матрицы X, а значит не знаем, сколько будет весов\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def activate(self, x):\n",
    "        return # Ваш код здесь\n",
    "        \n",
    "    def forward_pass(self, X):\n",
    "        \"\"\"\n",
    "        Рассчитывает ответ перцептрона при предъявлении набора объектов\n",
    "        :param: X -- матрица примеров размера (n, m), каждая строка - отдельный объект\n",
    "        :return: вектор размера (n, 1) из нулей и единиц с ответами перцептрона \n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        y_pred = np.zeros((n, 1))  # y_predicted - предсказанные классы\n",
    "        # Ваш код здесь\n",
    "        return y_pred\n",
    "    \n",
    "    def backward_pass(self, X, y, y_pred, learning_rate=0.005):\n",
    "        \"\"\"\n",
    "        Обновляет значения весов перцептрона в соответствии с этим объектом\n",
    "        :param: X -- матрица входов размера (n, m)\n",
    "                y -- вектор правильных ответов размера (n, 1)\n",
    "                learning_rate - \"скорость обучения\" (символ alpha в формулах выше)\n",
    "        В этом методе ничего возвращать не нужно\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "    \n",
    "    def fit(self, X, y, num_epochs=300):\n",
    "        \"\"\"\n",
    "        Спускаемся в минимум\n",
    "        :param: X -- матрица входов размера (n, m)\n",
    "                y -- вектор правильных ответов размера (n, 1)\n",
    "                num_epochs -- количество итераций обучения\n",
    "        :return: J_values -- вектор значений функции потерь\n",
    "        \"\"\"\n",
    "        self.w = np.zeros((X.shape[1], 1))  # столбец (m, 1)\n",
    "        self.b = 0  # смещение\n",
    "        J_values = []  # значения функции потерь на различных итерациях обновления весов\n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            # Ваш код здесь\n",
    "        \n",
    "        return J_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тестирование нейрона (3 балла)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь Вам нужно самим протестировать новый нейрон **на тех же данных** по аналогии с тем, как это было проделано с перцептроном.  (можете смело копировать код, только будьте осторожны - кое-что в нём всё же скорее всего придётся поправить).\n",
    "В итоге нужно вывести: \n",
    "* график, на котором будет показано, как изменяется функция потерь $J$ в зависимости от числа итераций обучения (1.5 балла)\n",
    "* график с раскраской выборки сигмоидальным нейроном (1.5 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь (можете использовать много ячеек)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nojupyter]",
   "language": "python",
   "name": "conda-env-nojupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
