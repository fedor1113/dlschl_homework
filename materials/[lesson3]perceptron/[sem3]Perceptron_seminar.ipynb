{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Школа глубокого обучения\n",
    "\n",
    "<a href=\"https://mipt.ru/science/labs/laboratoriya-neyronnykh-sistem-i-glubokogo-obucheniya/\"><img align=\"right\" src=\"https://avatars1.githubusercontent.com/u/29918795?v=4&s=200\" alt=\"DeepHackLab\" style=\"position:relative;top:-40px;right:10px;height:100px;\" /></a>\n",
    "\n",
    "\n",
    "\n",
    "### Физтех-Школа Прикладной математики и информатики МФТИ \n",
    "### Лаборатория нейронных сетей и глубокого обучения (DeepHackLab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перцептрон и его друзья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as p3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перцептрон: intro\n",
    "Попробуем разобраться с моделью перцептрона.\n",
    "Надеюсь, что это будет простое задание. \n",
    "\n",
    "![title](img/perceptron.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Сегодня мы будем пытаться научиться отличать яблоки от груш. Датасет состоит из трех признаков: желтизна, симметричность плода и собственно сама целевая переменная(0 - яблоки, 1 - груши)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/apples_pears.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pears = data[\"target\"] == 1\n",
    "apples = data[\"target\"] == 0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так данные то у нас есть, но неплохо бы понимать, что они из себя представляют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(data[apples].yellowness, data[apples].symmetry, color = \"red\")\n",
    "plt.scatter(data[pears].yellowness, data[pears].symmetry, color = \"yellow\")\n",
    "plt.xlabel(\"yellowness\")\n",
    "plt.ylabel(\"symmetry\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, w, b):\n",
    "        \"\"\"\n",
    "        :param w: вектор весов\n",
    "        :param b: bias\n",
    "        \"\"\"\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def _activate(self, x):\n",
    "        \"\"\"\n",
    "        Пороговая активационная функция перцептрона\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward_pass(self, input_matrix):\n",
    "        \"\"\"\n",
    "        Метод рассчитывает ответ перцептрона при предъявлении набора примеров\n",
    "        :param: input_matrix - матрица примеров размера (n, m), каждая строка - отдельный пример,\n",
    "        :return: вектор размера (n, 1) с ответами перцептрона\n",
    "        \"\"\"\n",
    "        pass\n",
    "    # Чего-то не хватает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну сейчас мы сделали модель, о которой говорили раньше. Попробуем теперь сделать упражнение прямо в ней. \n",
    "\n",
    "**Упражнение**: Возьмите вектор  \\begin{align}\n",
    "    \\vec{w} &= \\begin{bmatrix}\n",
    "           -1,5 \\\\\n",
    "           1 \\\\\n",
    "           1\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "  \n",
    "Напоминаю, что bias передается в конструктор класса( тут это первая координата)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_matrix = np.array([[0,0], [0,1], [1,0], [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per = Perceptron(<code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per.forward_pass(input_matrix).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "Рассмотрим работу этого алгоритма на простом примере.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda x: x**3-2*x**2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_prime(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1,2.5,1000)\n",
    "plt.plot(x,f(x))\n",
    "plt.xlim([-1,2.5])\n",
    "plt.ylim([0,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_old = 0\n",
    "x_new = 2 # Попробуйте различные нулевые значения для нашего алгоритма\n",
    "lr = 0.1  # темп\n",
    "precision = 0.001\n",
    "\n",
    "x_history, y_history = [x_new], [f(x_new)]\n",
    " \n",
    "while abs(x_new - x_old) > precision:\n",
    "    x_old = x_new\n",
    "    grad = <code>\n",
    "    x_new = <code>\n",
    "    x_history.append(x_new)\n",
    "    y_history.append(f(x_new))\n",
    "print(\"Предполагаемый минимум\", x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/searh_min.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 8])\n",
    "plt.plot(x, f(x), c=\"b\")\n",
    "plt.plot(x_history, y_history,c=\"r\", alpha=0.6)\n",
    "plt.scatter(x_history, y_history,c=\"g\")\n",
    "plt.xlim([-1,2.5])\n",
    "plt.ylim([0,3])\n",
    "plt.title(\"Градиентный спуск\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 6])\n",
    "plt.scatter(x_history,y_history,c=\"g\")\n",
    "plt.plot(x_history, y_history,c=\"r\")\n",
    "plt.plot(x,f(x), c=\"b\", alpha=0.6)\n",
    "plt.xlim([1.2,2.1])\n",
    "plt.ylim([0,3])\n",
    "plt.title(\"Приблизимся\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Друзья перцептрона\n",
    "\n",
    "Перцептрон это конечно круто, но это просто линейный нейрон с определенной активацией. А какие же еще есть нейроны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сигмоидальный\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+\\exp{-x}}$$\n",
    "\n",
    "![Sigma](img/sigmoid.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"сигмоидальная функция\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    \"\"\"Производная сигмоиды\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Гиперболический тангенс\n",
    "$th(x)=\\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$\n",
    "\n",
    "![Sigma](img/tanh.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RELU\n",
    "$f(x) =  max (0,x) $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потесть сам. Задание: нарисовать графики этих функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = -2\n",
    "stop  = 2\n",
    "step  = 0.2\n",
    "\n",
    "\n",
    "print('Различные активационные функции')\n",
    "print(' ==================================')\n",
    "print(' |  x   | sigmoid |  tanh  | relu |')\n",
    "print(' ==================================')\n",
    "for i in np.arange(start, stop, step):\n",
    "    print(' | {} | {} | {} | {} |'.format(i, sigmoid(i), tanh(i), relu(i)))\n",
    "print(' ==================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В скором времене вы обязательно поймете зачем нам куча этих активаций. И когда какую использовать.\n",
    "\n",
    "\n",
    "Так, мы написали очень не нужную вещь. Надо бы превратить теперь этот перцептрон с определенными весами во что-то, что действительно будет классифицировать объекты.\n",
    "![title](img/rozen_meme.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение перцептрона\n",
    "\n",
    "Реализуйте методы grad_step и gradient_descent на основании полученных знаний. Тем самым мы дадим нашему перцептрону возможность адаптироваться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #############################\n",
    "        # Ваш перцептрон появится ниже  #\n",
    "        ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, w, b):\n",
    "        \"\"\"\n",
    "        :param w: вектор весов\n",
    "        :param b: bias\n",
    "        \"\"\"\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def _activate(self, x):\n",
    "        return x > 0\n",
    "    \n",
    "    def forward_pass(self, input_vector):\n",
    "        \"\"\"\n",
    "        Метод рассчитывает ответ перцептрона при предъявлении набора примеров\n",
    "        :param: input_matrix - матрица примеров размера (n, m), каждая строка - отдельный пример,\n",
    "        :return: вектор размера (n, 1) с ответами перцептрона\n",
    "        \"\"\"\n",
    "\n",
    "        ############\n",
    "        # Ваш код  #\n",
    "        ############\n",
    "        pass\n",
    "    \n",
    "    def grad_step(self, example, y):\n",
    "        \"\"\"\n",
    "        Обновляет значения весов перцептрона в соответствии с этим примером\n",
    "        :example: вектор (m, 1)\n",
    "        :y: истинные значения\n",
    "        :return: размер ошибки, которая случилась на этом примере до изменения весов (0 или 1)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def train(self, input_matrix, y, max_steps=1e8):\n",
    "        \"\"\"\n",
    "        Спускаемся в минимум\n",
    "        :input_matrix: матрица входов размера (n, m),\n",
    "        :y: вектор правильных ответов размера (n, 1)\n",
    "        :max_steps: максимальное количество шагов.\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        errors = 1\n",
    "        while errors and i < max_steps:\n",
    "            i += 1\n",
    "            errors = 0\n",
    "            for example, answer in zip(input_matrix, y):\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_line(coefs):\n",
    "    \"\"\"\n",
    "    рисует разделяющую прямую, соответствующую весам, переданным в coefs = (weights, bias), \n",
    "    где weights - ndarray формы (2, 1), bias - число\n",
    "    \"\"\"\n",
    "    w, bias = coefs\n",
    "    a, b = - w[0][0] / w[1][0], - bias / w[1][0]\n",
    "    xx = np.linspace(*plt.xlim())\n",
    "    line.set_data(xx, a*xx + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.random.rand(2,4)\n",
    "perceptron_for_weights_line = Perceptron(W, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_by_step_errors(p, input_matrix, y, max_steps=1e6):\n",
    "    \"\"\"\n",
    "    обучает перцептрон последовательно на каждой строчке входных данных, \n",
    "    на каждом шаге обучения запоминает количество неправильно классифицированных примеров\n",
    "    \"\"\"\n",
    "    def count_errors():\n",
    "        return np.abs(p.forward_pass(input_matrix).astype(np.int) - y[:, None]).mean()\n",
    "    errors_list = [count_errors()]\n",
    "    i = 0\n",
    "    errors = 1\n",
    "    while errors and i < max_steps:\n",
    "        i += 1\n",
    "        errors = 0\n",
    "        for example, answer in zip(input_matrix, y):\n",
    "            example = example.reshape((1,example.size))\n",
    "            error = p.grad_step(example, answer)\n",
    "            errors += error\n",
    "            errors_list.append(count_errors())\n",
    "    return errors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data['target']\n",
    "W = np.random.random((2,1))\n",
    "plt.figure(figsize=[10, 8])\n",
    "perceptron_for_misclassification = Perceptron(W, 1)\n",
    "errors_list = step_by_step_errors(perceptron_for_misclassification, \\\n",
    "                                  input_matrix=data.iloc[:,:2].values, y=target.values, max_steps=10)\n",
    "plt.plot(errors_list);\n",
    "plt.ylabel(\"Number\")\n",
    "plt.xlabel(\"Steps\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights_vector(perceptron):\n",
    "    \"\"\"возвращает вектор из всех весов перцептрона, включая смещение\"\"\"\n",
    "    return np.array(list(perceptron.w.ravel()) + [perceptron.b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_by_step_distances(p, ideal, input_matrix, y, max_steps=1e6):\n",
    "    \"\"\"обучает перцептрон p и записывает каждое изменение расстояния от текущих весов до ideal\"\"\"\n",
    "    distances = [np.linalg.norm(get_weights_vector(p) - ideal)]\n",
    "    i = 0\n",
    "    errors = 1\n",
    "    while errors and i < max_steps:\n",
    "        i += 1\n",
    "        errors = 0\n",
    "        for example, answer in zip(input_matrix, y):\n",
    "            example = example.reshape((example.size, 1))\n",
    "            \n",
    "            error = p.grad_step(example, answer)\n",
    "            errors += error\n",
    "            if error:\n",
    "                distances.append(np.linalg.norm(get_weights_vector(p) - ideal))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "init_weights = np.random.random_sample(3)\n",
    "w, b = init_weights[:-1].reshape((2, 1)), init_weights[-1]\n",
    "ideal_p = Perceptron(w.copy(), b.copy())\n",
    "ideal_p.gradient_descent(data.iloc[:, :2].values, data['target'].values)\n",
    "ideal_weights = get_weights_vector(ideal_p)\n",
    "\n",
    "new_p = Perceptron(w.copy(), b.copy())\n",
    "distances = step_by_step_distances(new_p, ideal_weights, data.iloc[:, :2].values, data['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"Number of weight updates\")\n",
    "plt.title(\"Distance between good and current weights\")\n",
    "plt.plot(distances);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
